# Meraculous

This README describes the Meraculous

## Background

De novo whole genome assembly reconstructs genomic sequence from short,
overlapping, and potentially erroneous fragments called reads, such as those
typically generated by state-of-the-art high-throughput sequencers. Meraculous
[1] is one component in a multi-part, massively parallel de novo genome
assembly pipeline developed jointly by researchers at UC Berkeley, Lawrence
Berkeley National Lab, and the DOE Joint Genome Institute. Like its namesake
[2] (originally implemented in Perl), Meraculous constructs and traverses the
de Bruijn graph of all overlapping substrings of length k (k-mers) present in
the input dataset of redundant short sequence reads. By traversing the de
Bruijn graph, and discovering all (possibly disconnected) linear subgraphs,
Meraculous is able to construct high-quality contiguous sequences of genomic
data composed of (typically many of) the original reads. These resulting
sequences are known as contigs.

Unlike its namesake, Meraculous is implemented in Unified Parallel C, which was
chosen to support the one-sided model of communication that is required in
order to construct and later traverse the de Bruijn graph, represented as a
distributed hash table where the k-mers are the keys, in a scalable manner.
One-sided communication is necessary due to the complex, data dependent access
patterns encountered in the latter operations, where peers in communication,
extents of data access, and timings there are not known a priori.

## Algorithm

At the heart of the de Bruijn graph construction and traversal is the
distributed hash table representing the nodes of the graph. The keys of this
hash table are the k-mers (strings of genomic material of length k), while the
values are structures containing ancillary data necessary to support the later
traversal. The latter includes the highest probability extensions (i.e. next
genetic base) appearing immediately before / after that particular k-mer, flags
for determining the current state of the k-mer (i.e. whether it has been
visited yet in the traversal), a UPC pointer-to-shared pointing to a data
structure unique to the contig to which the particular k-mer is added during
traversal, a UPC lock for serializing access to the contig pointer, and a
handful of other fields.

All communications patterns in Meraculous are, in essence, random access. There
are, however, a number of optimizations intended to reduce fine grained
communication and concurrency control, including: (1) an "aggregating store"
optimization that enables bulk inserts into the distributed hash table during
construction, and (2) a lightweight synchronization scheme that minimizes
concurrency control overheads (e.g. when updating a particular k-mer's contig
pointer) during graph traversal.

In a nutshell:
1. In parallel, each process reads a unique, contiguous (on disk) partition of
   the pre-computed k-mer dataset;
2. Each of the N processes hashes its read k-mers and prepares inserts into the
   hash table for the N - 1 other processes (the hash determines both the
   "owner" process and the target bucket on that process), aggregating the
   inserts into per target-process local buffers;
3. Once a local buffer is full, it's sent to the target process for which it is
   bound. This requires an atomic fetch-add to reserve an offset in the
   target's receive buffer and a one-sided upc_memput to emplace the k-mers and
   associated data (e.g. extension bases) in bulk. This process is repeated
   until all locally read k-mer data has been inserted.
4. Traversal begins with each process selecting a locally owned k-mer as a
   "seed" at random, thereby defining a singleton contig which will now be
   extended;
5. Contig extension involves performing repeated lookups in the distributed hash
   table (i.e. small random reads). Specifically, starting from the seed k-mer,
   each process attempts to look up k-mers in hash table equal to the rightmost
   and leftmost k - 1 genetic bases in the current contig, complemented by the
   right and left high-probability extensions of the right and leftmost k-mers
   in the contig: i.e. k-mers

       {left_extension + contig[0:k-2], contig[1:k-1] + right_extension}

6. When the lookup succeeds, the found k-mer is marked as visited ("used") added
   to the current contig (by setting the associated contig pointer).

Care must be taken in testing whether a found k-mer can be or already has been
marked as used, which is implemented with an atomic compare-and-swap operation.
Further, processes that "collide" with each other by following the same contig
from different directions (and visiting the same k-mer concurrently) must be
carefully treated - particularly in merging their contig structures. For more
details on the lightweight synchronization scheme used by Meraculous for this
purpose, please see [1].

## Building Meraculous

### Dependencies

Meraculous requires a UPC compiler supporting both (a) standard UPC language
functionality and (b) language extensions for 64-bit atomic fetch-and-add and
compare-and-swap operations. For example, Berkeley UPC [3], a portable high-
performance UPC compiler and GASNet-based runtime, would satisfy these
requirements (with FA and CS supported via `bupc_atomic*` extensions). Many
vendor-specific compilers support analogous functionality (such as the Cray
Compiler Environment, with FA and CS supported via `_amo_*_upc` extensions).

There are no other dependencies required to build Meraculous.

### Compilation

Out of the box, the Meraculous makefile supporte compilation under both
Berkeley UPC and the Cray Compiler Environment. This can be controlled via the
`UPC_COMPILER` variable. The latter sets the name of the UPC compiler
executable, relevant (suggested) compiler-specific options, and preprocessor
macros that select which atomic remote fetch-and-add and compare-and-swap
expensions to use. The latter take effect in `meraculous.h`. 

To add support for an additional UPC compiler / runtime, one can simply add a
new conditional case to the makefile (i.e. for a new `UPC_COMPILER`) and
associated macro definitions to `meraculous.h`.

In addition, you will need to specify a C++ compiler that both supports the
C++11 standard, and the object files from which can be linked by the chosen UPC
compiler (i.e. by potentially adding `-lstdc++` or the like to the UPC link
line).

Once the compiler types and options are set up, you should be able to simply
run `make`, which will produce the `meraculous-51` executable (the "51" refers
to the k-mer length, which is set at compile time).

### Validation of code changes

In the `tests/` folder, we include a post-processing script and associated
"ground truth" output for the small (< 1 GB) single-chromosome human dataset.
The latter may be used to validate any code changes you make. Also included is
an example batch script (here, for the PBS resource manager and Berkeley UPC)
that is properly configured for running this test.

Dependencies: You must download the `human-chr14.txt.ufx.bin` dataset.

Steps to validate:
1. Build Meraculous using:

      make test-mode

   and copy the resulting binary (`meraculous-51-testing`) into the `tests/`
   directory (this binary differs from that built by the default target, in
   that it actually saves the resulting contigs to disk for verification).
2. Copy in the `human-chr14.txt.ufx.bin` dataset as well
3. Run the code, using the same options as shown in `run_meraculous.pbs`
4. Run the `check_results.sh` shell script

The latter step will check the contigs resulting from the test run against the
"ground truth" results and display whether or not the test has passed.

## Benchmark runs

Example batch submission scripts for the PBS resource manager and Berkeley UPC
are included in the form of `example_X.pbs` for each of the benchmark sizes (X
= {small, medium, large}) enumerated below.

Note that, depending on the UPC compiler and runtime, you may need to specify a
fixed shared symmetric heap size (or limit) at launch. Under Berkeley UPC, for
example, this is done via the `-shared-heap` command line argument to `upcrun`.
Note that Meraculous computes an estimated upper bound on the minimum required
shared heap size at launch, which is printed to stdout.

### Run rules

Each test problem is accompanied by a run script demonstrating exact set of
command line arguments that must be supplied to Meraculous for that particular
problem (the `required_flags` variable). As with the validation test mentioned
above, these example run scripts are configured for Berkeley UPC and the PBS
resource manager.

For each test problem, please report the non-I/O portion of the total time to
solution, defined as the the total time

    Total time is : XXXX seconds

minus the maximum I/O time across all processes

    Maximum IO time : XXXX seconds

in the supplied spreadsheet.

Overall performance is judged based on the total time to solution minus the I/O
time (the latter is not being assessed in this benchmark). Feel free to report
the best-case (total time, I/O time) pair you achieve.

**Code changes**: As with other benchmarks, you are allowed to explore
optimizations to this code, as long as they do not impact its functionality.
Specifically, we ask that:
1. All modified code used in collecting the above performance data is returned
   with the timing data; and
2. All code modifications must be validated as described above (see "Validation
   of code changes").

### Small

The "small" dataset is sized to fit on only a couple (1-3) modern-day compute
nodes, and is based on a random subset of human genome data (approximately 25%,
selected by chromosome to ensure biologically plausible data distribution). The
resulting input dataset `bwa-25pct.list.ufx.bin` occupiess ~ 28 GB on disk.

### Medium

The "medium" dataset represents contig generation for a full human genome. The
associated input file is `human.fastqs.ufx.bin.trim.min3` and occupies ~ 107 GB
on disk.

### Large

The "large" dataset represents contig generation for a metagenomic dataset
collected from wetlands mud (`metagenomefiles.txt.ufx.bin`) and occupies ~ 1 TB
on disk.

## References

[1] E. Georganas, A. Buluc, J. Chapman, L. Oliker, D. Rokhsar, and K. Yelick,
“Parallel De Bruijn Graph Construction and Traversal for De Novo Genome
Assembly,” in Proceedings of the International Conference for High Performance
Computing, Networking, Storage and Analysis (SC’14), 2014.

[2] J. A. Chapman, I. Ho, S. Sunkara, S. Luo, G. P. Schroth, and D. S. Rokhsar,
“Meraculous: De novo genome assembly with short paired-end reads,” PLoS ONE,
vol. 6, no. 8, p. e23501, 08 2011.

[3] http://upc.lbl.gov/
